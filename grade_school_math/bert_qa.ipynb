{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 0: import module for bert_QA project</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 0\n",
    "import json\n",
    "import os\n",
    "from dataset import read_jsonl\n",
    "import re\n",
    "# step 1\n",
    "from sklearn.model_selection import train_test_split\n",
    "# step 4\n",
    "from transformers import AutoTokenizer, BertForQuestionAnswering\n",
    "from transformers import AdamW\n",
    "# step 6\n",
    "import torch as th\n",
    "# step 7\n",
    "from torch.utils.data import DataLoader\n",
    "# step 10\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "os.chdir('/home/sangmin/grade-school-math/grade_school_math/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 1: Retrieve and Store the data</h1>\n",
    "Here I take and store the texts, queries and answers from the train and validation .json files. I save these informations into lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"data/train.jsonl\")\n",
    "objs = read_jsonl(path)\n",
    "\n",
    "texts = []\n",
    "queries = []\n",
    "answers = []\n",
    "\n",
    "for i in objs:\n",
    "\n",
    "    answer_info = {}\n",
    "\n",
    "    an = i['answer']\n",
    "    co = re.findall('.+\\n#', an)\n",
    "    ans = re.findall('\\d+$', an)\n",
    "\n",
    "    context = co[0]\n",
    "    answer_info['text'] = ans[0]\n",
    "    answer_info['answer_start'] = context.rfind('>>') + 2\n",
    "    question = i['question']\n",
    "        \n",
    "    texts.append(context)\n",
    "    answers.append(answer_info)\n",
    "    queries.append(question)\n",
    "\n",
    "train_texts, val_texts, train_queries, val_queries, train_answers, val_answers = train_test_split(texts, queries, answers, test_size=0.15, shuffle=True)\n",
    "\n",
    "#{'question': 'Nina enjoys keeping insects as pets. She has 3 spiders and 50 ants. Each spider has 8 eyes. Each ant has 2 eyes. How many eyes are there in total among Nina’s pet insects?', \n",
    "#'answer': 'The number of eyes from the spiders is 3 * 8 = <<3*8=24>>24 eyes\\nThe number of eyes from the ants is 50 * 2 = <<50*2=100>>100 eyes\\nThe total number of eyes among Nina’s insects is 24 + 100 = <<24+100=124>>124 eyes\\n#### 124'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Step 2: Check the data</H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we have 7473 passages, queries and answers from the training data. The answer is stored in a dictionary with the specific answer in the \"text\" cell and the accurate character index that the answer is started in cell \"answer start\". As we observe, we need to fill the information about the exact index of the character that the answer is ending from the referance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6352\n",
      "6352\n",
      "6352\n"
     ]
    }
   ],
   "source": [
    "print(len(train_texts))\n",
    "print(len(train_queries))\n",
    "print(len(train_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage:  ['Therefore (Number of Minutes) = 4\\n#', \"A quarter of this time is spent on commercials, so that's 180 minutes / 4 = <<180/4=45>>45 minutes\\n#\"]\n",
      "Query:  [\"Erik's dog can run 24 miles per hour. It is chasing a rabbit that can run 15 miles per hour. The rabbit has a head start of .6 miles. How many minutes does it take for the dog to catch up to the rabbit?\", 'One-fourth of the airing time of a television program is spent on commercials. If there are 6 thirty-minute programs, how many minutes are spent on commercials for the whole duration of the 6 programs?']\n",
      "Answer:  [{'text': '4', 'answer_start': 1}, {'text': '45', 'answer_start': 88}]\n"
     ]
    }
   ],
   "source": [
    "print(\"Passage: \",train_texts[0:2])  \n",
    "print(\"Query: \",train_queries[0:2])\n",
    "print(\"Answer: \",train_answers[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1121\n",
      "1121\n",
      "1121\n"
     ]
    }
   ],
   "source": [
    "print(len(val_texts))\n",
    "print(len(val_queries))\n",
    "print(len(val_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage:  There are 24 more children than adults because 72 - 48 = <<72-48=24>>24\n",
      "#\n",
      "Query:  A church has 120 members. 40% are adults. The rest are children. How many children more children are there than adults?\n",
      "Answer:  {'text': '24', 'answer_start': 69}\n"
     ]
    }
   ],
   "source": [
    "print(\"Passage: \",val_texts[1])  \n",
    "print(\"Query: \",val_queries[1])\n",
    "print(\"Answer: \",val_answers[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 3: Find the end position character</h1>\n",
    "Because Bert model needs both start and end position characters of the answer, I have to find it and store it for later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find end position character in train data.\n",
    "for answer, text in zip(train_answers, train_texts):\n",
    "    real_answer = answer['text']\n",
    "    start_idx = answer['answer_start']\n",
    "    end_idx = start_idx + len(real_answer) -1\n",
    "    answer['answer_end'] = end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find end position character in valid data.\n",
    "for answer, text in zip(val_answers, val_texts):\n",
    "    real_answer = answer['text']\n",
    "    start_idx = answer['answer_start']\n",
    "    end_idx = start_idx + len(real_answer) -1\n",
    "    answer['answer_end'] = end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage:  ['Therefore (Number of Minutes) = 4\\n#', \"A quarter of this time is spent on commercials, so that's 180 minutes / 4 = <<180/4=45>>45 minutes\\n#\"]\n",
      "Query:  [\"Erik's dog can run 24 miles per hour. It is chasing a rabbit that can run 15 miles per hour. The rabbit has a head start of .6 miles. How many minutes does it take for the dog to catch up to the rabbit?\", 'One-fourth of the airing time of a television program is spent on commercials. If there are 6 thirty-minute programs, how many minutes are spent on commercials for the whole duration of the 6 programs?']\n",
      "Answer:  [{'text': '4', 'answer_start': 1, 'answer_end': 1}, {'text': '45', 'answer_start': 88, 'answer_end': 89}]\n"
     ]
    }
   ],
   "source": [
    "#double check for data including answer_end index\n",
    "print(\"Passage: \",train_texts[0:2])  \n",
    "print(\"Query: \",train_queries[0:2])\n",
    "print(\"Answer: \",train_answers[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 4: Tokenize passages and queries</h1>\n",
    "In this task is asked to select the BERT-base pretrained model “bert-base-uncased” for the tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "train_encodings = tokenizer(train_texts, train_queries, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, val_queries, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 5: Convert the start-end positions to tokens start-end positions</h1>\n",
    "In this task is asked to select the BERT-base pretrained model “bert-base-uncased” for the tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "  start_positions = []\n",
    "  end_positions = []\n",
    "\n",
    "  count = 0\n",
    "  for i in range(len(answers)):\n",
    "    start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "    end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n",
    "\n",
    "    # if start position is None, the answer passage has been truncated\n",
    "    if start_positions[-1] is None:\n",
    "      start_positions[-1] = tokenizer.model_max_length\n",
    "      \n",
    "    # if end position is None, the 'char_to_token' function points to the space after the correct token, so add - 1\n",
    "    if end_positions[-1] is None:\n",
    "      end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] - 1)\n",
    "      # if end position is still None the answer passage has been truncated\n",
    "      if end_positions[-1] is None:\n",
    "        count += 1\n",
    "        end_positions[-1] = tokenizer.model_max_length\n",
    "\n",
    "  print(count)\n",
    "\n",
    "  # Update the data in dictionary\n",
    "  encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "add_token_positions(train_encodings, train_answers)\n",
    "add_token_positions(val_encodings, val_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=253, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 6: Create a Dataset class</h1>\n",
    "Create a GSM8Kdataset class for BERT (inherits from torch.utils.data.Dataset), that helped me to train and validate my previous data more easily and convert encodings to datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gsm8kDataset(th.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: th.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = gsm8kDataset(train_encodings)\n",
    "val_dataset = gsm8kDataset(val_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, val in train_encodings.items():\n",
    "#     print({key: th.tensor(val[1])} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 7: Use of DataLoader</h1>\n",
    "I put my previous data to DataLoader, so as to split them in \"pieces\" of 8 batch size. I will explain the selection of this value of batch size later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 8: Use GPU</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = th.device('cuda:0' if th.cuda.is_available()\n",
    "                      else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 9: Build the Bert model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/sangmin/anaconda3/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "# optim = AdamW(model.parameters(), lr=3e-5)\n",
    "# optim = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# epochs = 2\n",
    "epochs = 5\n",
    "# epochs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 10: Train and Evaluate Model</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############Train############\n",
      "Batch 1000 / 1588 \n",
      "Loss: 0.0 \n",
      "\n",
      "############Evaluate############\n",
      "\n",
      "-------Epoch  1 -------\n",
      "Training Loss: 0.10510487643481409 \n",
      "Validation Loss: 0.02983678684055296 \n",
      "Time:  97.90031433105469 \n",
      "----------------------- \n",
      "\n",
      "\n",
      "############Train############\n",
      "Batch 1000 / 1588 \n",
      "Loss: 0.0 \n",
      "\n",
      "############Evaluate############\n",
      "\n",
      "-------Epoch  2 -------\n",
      "Training Loss: 0.0454421562862486 \n",
      "Validation Loss: 0.03903035874568834 \n",
      "Time:  96.94937419891357 \n",
      "----------------------- \n",
      "\n",
      "\n",
      "############Train############\n",
      "Batch 1000 / 1588 \n",
      "Loss: 0.2 \n",
      "\n",
      "############Evaluate############\n",
      "\n",
      "-------Epoch  3 -------\n",
      "Training Loss: 0.04325524010956171 \n",
      "Validation Loss: 0.029715275485882896 \n",
      "Time:  96.83696913719177 \n",
      "----------------------- \n",
      "\n",
      "\n",
      "############Train############\n",
      "Batch 1000 / 1588 \n",
      "Loss: 0.0 \n",
      "\n",
      "############Evaluate############\n",
      "\n",
      "-------Epoch  4 -------\n",
      "Training Loss: 0.03597263681101291 \n",
      "Validation Loss: 0.041760344591062724 \n",
      "Time:  96.18105220794678 \n",
      "----------------------- \n",
      "\n",
      "\n",
      "############Train############\n",
      "Batch 1000 / 1588 \n",
      "Loss: 0.0 \n",
      "\n",
      "############Evaluate############\n",
      "\n",
      "-------Epoch  5 -------\n",
      "Training Loss: 0.022471778146429026 \n",
      "Validation Loss: 0.04020783342110467 \n",
      "Time:  95.47561478614807 \n",
      "----------------------- \n",
      "\n",
      "\n",
      "Total training and evaluation time:  483.34446573257446\n"
     ]
    }
   ],
   "source": [
    "whole_train_eval_time = time.time()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print_every = 1000\n",
    "\n",
    "# writer = SummaryWriter() #for visualization.\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  epoch_time = time.time()\n",
    "\n",
    "  # Set model in train mode\n",
    "  model.train()\n",
    "    \n",
    "  loss_of_epoch = 0\n",
    "\n",
    "  print(\"############Train############\")\n",
    "\n",
    "  for batch_idx,batch in enumerate(train_loader): \n",
    "    \n",
    "    optim.zero_grad()\n",
    "\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_positions = batch['start_positions'].to(device)\n",
    "    end_positions = batch['end_positions'].to(device)\n",
    "    \n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "    loss = outputs[0]\n",
    "    # writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "    # do a backwards pass \n",
    "    loss.backward()\n",
    "    # update the weights\n",
    "    optim.step()\n",
    "    # Find the total loss\n",
    "    loss_of_epoch += loss.item()\n",
    "\n",
    "    if (batch_idx+1) % print_every == 0:\n",
    "      print(\"Batch {:} / {:}\".format(batch_idx+1,len(train_loader)),\"\\nLoss:\", round(loss.item(),1),\"\\n\")\n",
    "\n",
    "  loss_of_epoch /= len(train_loader)\n",
    "  train_losses.append(loss_of_epoch)\n",
    "\n",
    "  ##########Evaluation##################\n",
    "\n",
    "  # Set model in evaluation mode\n",
    "  model.eval()\n",
    "\n",
    "  print(\"############Evaluate############\")\n",
    "\n",
    "  loss_of_epoch = 0\n",
    "\n",
    "  for batch_idx,batch in enumerate(val_loader):\n",
    "    \n",
    "    with th.no_grad():\n",
    "\n",
    "      input_ids = batch['input_ids'].to(device)\n",
    "      attention_mask = batch['attention_mask'].to(device)\n",
    "      start_positions = batch['start_positions'].to(device)\n",
    "      end_positions = batch['end_positions'].to(device)\n",
    "      \n",
    "      outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "      loss = outputs[0]\n",
    "      # writer.add_scalar(\"Loss/val\", loss, epoch)\n",
    "      # Find the total loss\n",
    "      loss_of_epoch += loss.item()\n",
    "\n",
    "    # if (batch_idx+1) % print_every == 0:\n",
    "    #    print(\"Batch {:} / {:}\".format(batch_idx+1,len(val_loader)),\"\\nLoss:\", round(loss.item(),1),\"\\n\")\n",
    "\n",
    "  loss_of_epoch /= len(val_loader)\n",
    "  val_losses.append(loss_of_epoch)\n",
    "\n",
    "  # Print each epoch's time and train/val loss \n",
    "  print(\"\\n-------Epoch \", epoch+1,\n",
    "        \"-------\"\n",
    "        \"\\nTraining Loss:\", train_losses[-1],\n",
    "        \"\\nValidation Loss:\", val_losses[-1],\n",
    "        \"\\nTime: \",(time.time() - epoch_time),\n",
    "        \"\\n-----------------------\",\n",
    "        \"\\n\\n\")\n",
    "\n",
    "print(\"Total training and evaluation time: \", (time.time() - whole_train_eval_time))\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 11: Visualization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fcd1c023b50>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(15,10))\n",
    "\n",
    "ax.set_title(\"Train and Validation Losses\",size=20)\n",
    "ax.set_ylabel('Loss', fontsize = 20) \n",
    "ax.set_xlabel('Epochs', fontsize = 25) \n",
    "ax.plot(train_losses)\n",
    "ax.plot(val_losses)\n",
    "ax.legend(('Train','Val'),loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TEST</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Make the prediction and evaluate it</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(context,query):\n",
    "  \n",
    "  inputs = tokenizer.encode_plus(query, context, return_tensors='pt')\n",
    "\n",
    "  with th.no_grad():\n",
    "    outputs = model(**inputs).to(device)\n",
    "\n",
    "  answer_start = th.argmax(outputs[0])  # get the most likely beginning of answer with the argmax of the score\n",
    "  answer_end = th.argmax(outputs[1]) + 1 \n",
    "\n",
    "  answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
    "\n",
    "  return answer\n",
    "\n",
    "def normalize_text(s):\n",
    "  \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "  import string, re\n",
    "\n",
    "  def remove_articles(text):\n",
    "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "    return re.sub(regex, \" \", text)\n",
    "\n",
    "  def white_space_fix(text):\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "  def remove_punc(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "  def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "  return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "  pred_tokens = normalize_text(prediction).split()\n",
    "  truth_tokens = normalize_text(truth).split()\n",
    "  \n",
    "  # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "  if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "    return int(pred_tokens == truth_tokens)\n",
    "  \n",
    "  common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "  \n",
    "  # if there are no common tokens then f1 = 0\n",
    "  if len(common_tokens) == 0:\n",
    "    return 0\n",
    "  \n",
    "  prec = len(common_tokens) / len(pred_tokens)\n",
    "  rec = len(common_tokens) / len(truth_tokens)\n",
    "  \n",
    "  return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_an_answer(context,query,answer):\n",
    "\n",
    "  prediction = predict(context,query)\n",
    "  em_score = compute_exact_match(prediction, answer)\n",
    "  f1_score = compute_f1(prediction, answer)\n",
    "\n",
    "  print(f\"Question: {query}\")\n",
    "  print(f\"Prediction: {prediction}\")\n",
    "  print(f\"True Answer: {answer}\")\n",
    "  print(f\"EM: {em_score}\")\n",
    "  print(f\"F1: {f1_score}\")\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Test my model</H1>\n",
    "Here I give some examples to my model to see how well I trained it. I started with more easier examples and then I gave it more complex ones.\n",
    "\n",
    "For extractive textual QA tasks, we usually adopt two evaluation metrics, which measure exact match and partially overlapped scores respectively. also EM is more reasonable for GSM8K data\n",
    "\n",
    "- EM(Exact Match) : measures whether the predicted answer exactly matches the ground-truth answers. If the exact matching occurs, then assigns 1.0, otherwise assigns 0.0.\n",
    "- F1 Score : computes the average word overlap between predicted and ground-truth answers, which can ensure both of precision and recall rate are optimized at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is test dataset\n",
    "path = os.path.join(\"data/test.jsonl\")\n",
    "objs = read_jsonl(path)\n",
    "\n",
    "texts = []\n",
    "queries = []\n",
    "answers = []\n",
    "\n",
    "for i in objs:\n",
    "\n",
    "    answer_info = {}\n",
    "\n",
    "    an = i['answer']\n",
    "    co = re.findall('.+\\n#', an)\n",
    "    ans = re.findall('\\d+$', an)\n",
    "\n",
    "    context = co[0]\n",
    "    answer_info['text'] = ans[0]\n",
    "    answer_info['answer_start'] = context.rfind('>>') + 2\n",
    "    question = i['question']\n",
    "        \n",
    "    texts.append(context)\n",
    "    answers.append(answer_info)\n",
    "    queries.append(question)\n",
    "\n",
    "test_texts, test_queries, test_answers = texts, queries, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_queries[0]\n",
    "test_answers[0]['text']\n",
    "test_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q = test_queries[0]\n",
    "# q\n",
    "# test_texts[0]\n",
    "a = test_answers[0]['text']\n",
    "[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = 'She makes 9 * 2  == $<<9*2=18>>18 every day at the farmer’s market.\\n#'\n",
    "queries = 'Janets ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers market?'\n",
    "queries = [queries]\n",
    "answers ='18'\n",
    "answers = [answers]\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16476/2324493657.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mgive_an_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "for q,a in zip(queries.to(device), answers.to(device)):\n",
    "  give_an_answer(context,q,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input, output and indices must be on the current device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16476/2250837323.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_queries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_answers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mgive_an_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_16476/3660604505.py\u001b[0m in \u001b[0;36mgive_an_answer\u001b[0;34m(context, query, answer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgive_an_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mem_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_exact_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mf1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_f1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16476/1599032040.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(context, query)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0manswer_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# get the most likely beginning of answer with the argmax of the score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1837\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         )\n\u001b[1;32m   1841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m         )\n\u001b[1;32m    996\u001b[0m         encoder_outputs = self.encoder(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input, output and indices must be on the current device"
     ]
    }
   ],
   "source": [
    "for q,a in zip(test_queries[0],test_answers[0]['text']):\n",
    "  give_an_answer(test_texts[0],q,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= 'abc dedf gefj'\n",
    "b = a.split()\n",
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2abf55bda1c53852352d4e16de7f91e46e9520816b382a01d9abf8d98ce130e3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

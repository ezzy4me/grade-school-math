{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 0: import module for distillbert_QA project</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 0\n",
    "import json\n",
    "import os\n",
    "from dataset import read_jsonl\n",
    "import re\n",
    "# step 1\n",
    "from sklearn.model_selection import train_test_split\n",
    "# step 4\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForQuestionAnswering\n",
    "from transformers import AdamW\n",
    "# step 6\n",
    "import torch as th\n",
    "# step 7\n",
    "from torch.utils.data import DataLoader\n",
    "# step 10\n",
    "import time\n",
    "\n",
    "os.chdir('/home/sangmin/grade-school-math/grade_school_math/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 1: Retrieve and Store the data</h1>\n",
    "Here I take and store the texts, queries and answers from the train and validation .json files. I save these informations into lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"data/train.jsonl\")\n",
    "objs = read_jsonl(path)\n",
    "\n",
    "texts = []\n",
    "queries = []\n",
    "answers = []\n",
    "\n",
    "for i in objs:\n",
    "\n",
    "    answer_info = {}\n",
    "\n",
    "    an = i['answer']\n",
    "    co = re.findall('.+\\n#', an)\n",
    "    ans = re.findall('\\d+$', an)\n",
    "\n",
    "    context = co[0]\n",
    "    answer_info['text'] = ans[0]\n",
    "    answer_info['answer_start'] = context.rfind('>>') + 2\n",
    "    question = i['question']\n",
    "        \n",
    "    texts.append(context)\n",
    "    answers.append(answer_info)\n",
    "    queries.append(question)\n",
    "\n",
    "train_texts, val_texts, train_queries, val_queries, train_answers, val_answers = train_test_split(texts, queries, answers, test_size=0.15, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Step 2: Check the data</H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we have 7473 passages, queries and answers from the training data. The answer is stored in a dictionary with the specific answer in the \"text\" cell and the accurate character index that the answer is started in cell \"answer start\". As we observe, we need to fill the information about the exact index of the character that the answer is ending from the referance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6352\n",
      "6352\n",
      "6352\n"
     ]
    }
   ],
   "source": [
    "print(len(train_texts))\n",
    "print(len(train_queries))\n",
    "print(len(train_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage:  ['Hence, each part is 64 inches / 4 parts = <<64/4=16>>16 inches/part.\\n#', \"It's 2021 and Julia is 42 years old so she was born in 2021-42 = <<2021-42=1979>>1979\\n#\"]\n",
      "Query:  ['A piece of wire 5 feet 4 inches long was divided into 4 equal parts. How long was each part in inches if 1 foot is equal to 12 inches?', 'In 2021, Wayne is 37 years old.  His brother Peter is 3 years older than him and their sister Julia is 2 years older than Peter.  What year was Julia born in?']\n",
      "Answer:  [{'text': '16', 'answer_start': 53, 'answer_end': 54}, {'text': '1979', 'answer_start': 81, 'answer_end': 84}]\n"
     ]
    }
   ],
   "source": [
    "print(\"Passage: \",train_texts[0:2])  \n",
    "print(\"Query: \",train_queries[0:2])\n",
    "print(\"Answer: \",train_answers[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1121\n",
      "1121\n",
      "1121\n"
     ]
    }
   ],
   "source": [
    "print(len(val_texts))\n",
    "print(len(val_queries))\n",
    "print(len(val_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage:  His original order was $25 and they added $10.00 so his new order is 25+10 = $<<25+10=35.00>>35.00\n",
      "#\n",
      "Query:  Ian used a grocery delivery app to have his groceries delivered.  His original order was $25 before delivery and tip.  He noticed that 3 items changed on his order.  A $0.99 can of tomatoes was replaced by a $2.20 can of tomatoes, his $1.00 lettuce was replaced with $1.75 head of lettuce and his $1.96 celery was replaced with celery that cost $2.00.  Delivery and tip came to a total of $8.00.  How much is his new bill now, with the food substitutes and delivery/tip?\n",
      "Answer:  {'text': '35', 'answer_start': 93, 'answer_end': 94}\n"
     ]
    }
   ],
   "source": [
    "print(\"Passage: \",val_texts[1])  \n",
    "print(\"Query: \",val_queries[1])\n",
    "print(\"Answer: \",val_answers[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 3: Find the end position character</h1>\n",
    "Because distilBert model needs both start and end position characters of the answer, I have to find it and store it for later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find end position character in train data.\n",
    "for answer, text in zip(train_answers, train_texts):\n",
    "    real_answer = answer['text']\n",
    "    start_idx = answer['answer_start']\n",
    "    end_idx = start_idx + len(real_answer) -1\n",
    "    answer['answer_end'] = end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find end position character in valid data.\n",
    "for answer, text in zip(val_answers, val_texts):\n",
    "    real_answer = answer['text']\n",
    "    start_idx = answer['answer_start']\n",
    "    end_idx = start_idx + len(real_answer) -1\n",
    "    answer['answer_end'] = end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage:  ['Hence, each part is 64 inches / 4 parts = <<64/4=16>>16 inches/part.\\n#', \"It's 2021 and Julia is 42 years old so she was born in 2021-42 = <<2021-42=1979>>1979\\n#\"]\n",
      "Query:  ['A piece of wire 5 feet 4 inches long was divided into 4 equal parts. How long was each part in inches if 1 foot is equal to 12 inches?', 'In 2021, Wayne is 37 years old.  His brother Peter is 3 years older than him and their sister Julia is 2 years older than Peter.  What year was Julia born in?']\n",
      "Answer:  [{'text': '16', 'answer_start': 53, 'answer_end': 54}, {'text': '1979', 'answer_start': 81, 'answer_end': 84}]\n"
     ]
    }
   ],
   "source": [
    "#double check for data including answer_end index\n",
    "print(\"Passage: \",train_texts[0:2])  \n",
    "print(\"Query: \",train_queries[0:2])\n",
    "print(\"Answer: \",train_answers[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 4: Tokenize passages and queries</h1>\n",
    "In this task is asked to select the distilBERT-base pretrained model “bert-base-uncased” for the tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4c30dd51b6466bb39030908f388a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "train_encodings = tokenizer(train_texts, train_queries, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, val_queries, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 5: Convert the start-end positions to tokens start-end positions</h1>\n",
    "In this task is asked to select the distilBERT-base pretrained model “distilbert-base-uncased” for the tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "  start_positions = []\n",
    "  end_positions = []\n",
    "\n",
    "  count = 0\n",
    "  for i in range(len(answers)):\n",
    "    start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "    end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n",
    "\n",
    "    # if start position is None, the answer passage has been truncated\n",
    "    if start_positions[-1] is None:\n",
    "      start_positions[-1] = tokenizer.model_max_length\n",
    "      \n",
    "    # if end position is None, the 'char_to_token' function points to the space after the correct token, so add - 1\n",
    "    if end_positions[-1] is None:\n",
    "      end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] - 1)\n",
    "      # if end position is still None the answer passage has been truncated\n",
    "      if end_positions[-1] is None:\n",
    "        count += 1\n",
    "        end_positions[-1] = tokenizer.model_max_length\n",
    "\n",
    "  print(count)\n",
    "\n",
    "  # Update the data in dictionary\n",
    "  encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "add_token_positions(train_encodings, train_answers)\n",
    "add_token_positions(val_encodings, val_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 6: Create a Dataset class</h1>\n",
    "Create a GSM8Kdataset class for distilBERT (inherits from torch.utils.data.Dataset), that helped me to train and validate my previous data more easily and convert encodings to datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gsm8kDataset(th.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: th.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = gsm8kDataset(train_encodings)\n",
    "val_dataset = gsm8kDataset(val_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 7: Use of DataLoader</h1>\n",
    "I put my previous data to DataLoader, so as to split them in \"pieces\" of 8 batch size. I will explain the selection of this value of batch size later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 7: Use of DataLoader</h1>\n",
    "I put my previous data to DataLoader, so as to split them in \"pieces\" of 4 batch size. I will explain the selection of this value of batch size later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 8: Use GPU</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = th.device('cuda:0' if th.cuda.is_available()\n",
    "                      else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f09d26d7774ed39be9154e7f557191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/sangmin/anaconda3/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased').to(device)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "epochs = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 10: Train and Evaluate Model</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############Train############\n",
      "Batch 1000 / 1588 \n",
      "Loss: 0.0 \n",
      "\n",
      "############Evaluate############\n",
      "\n",
      "-------Epoch  1 -------\n",
      "Training Loss: 0.024229531170967378 \n",
      "Validation Loss: 0.0645959948257034 \n",
      "Time:  58.82606482505798 \n",
      "----------------------- \n",
      "\n",
      "\n",
      "############Train############\n",
      "Batch 1000 / 1588 \n",
      "Loss: 0.0 \n",
      "\n",
      "############Evaluate############\n",
      "\n",
      "-------Epoch  2 -------\n",
      "Training Loss: 0.021380648441208617 \n",
      "Validation Loss: 0.032404276124595954 \n",
      "Time:  59.08175182342529 \n",
      "----------------------- \n",
      "\n",
      "\n",
      "############Train############\n",
      "Batch 1000 / 1588 \n",
      "Loss: 0.0 \n",
      "\n",
      "############Evaluate############\n",
      "\n",
      "-------Epoch  3 -------\n",
      "Training Loss: 0.011682988612927867 \n",
      "Validation Loss: 0.044793760267119884 \n",
      "Time:  59.06923294067383 \n",
      "----------------------- \n",
      "\n",
      "\n",
      "Total training and evaluation time:  176.97829008102417\n"
     ]
    }
   ],
   "source": [
    "whole_train_eval_time = time.time()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print_every = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  epoch_time = time.time()\n",
    "\n",
    "  # Set model in train mode\n",
    "  model.train()\n",
    "    \n",
    "  loss_of_epoch = 0\n",
    "\n",
    "  print(\"############Train############\")\n",
    "\n",
    "  for batch_idx,batch in enumerate(train_loader): \n",
    "    \n",
    "    optim.zero_grad()\n",
    "\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_positions = batch['start_positions'].to(device)\n",
    "    end_positions = batch['end_positions'].to(device)\n",
    "    \n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "    loss = outputs[0]\n",
    "    # do a backwards pass \n",
    "    loss.backward()\n",
    "    # update the weights\n",
    "    optim.step()\n",
    "    # Find the total loss\n",
    "    loss_of_epoch += loss.item()\n",
    "\n",
    "    if (batch_idx+1) % print_every == 0:\n",
    "      print(\"Batch {:} / {:}\".format(batch_idx+1,len(train_loader)),\"\\nLoss:\", round(loss.item(),1),\"\\n\")\n",
    "\n",
    "  loss_of_epoch /= len(train_loader)\n",
    "  train_losses.append(loss_of_epoch)\n",
    "\n",
    "  ##########Evaluation##################\n",
    "\n",
    "  # Set model in evaluation mode\n",
    "  model.eval()\n",
    "\n",
    "  print(\"############Evaluate############\")\n",
    "\n",
    "  loss_of_epoch = 0\n",
    "\n",
    "  for batch_idx,batch in enumerate(val_loader):\n",
    "    \n",
    "    with th.no_grad():\n",
    "\n",
    "      input_ids = batch['input_ids'].to(device)\n",
    "      attention_mask = batch['attention_mask'].to(device)\n",
    "      start_positions = batch['start_positions'].to(device)\n",
    "      end_positions = batch['end_positions'].to(device)\n",
    "      \n",
    "      outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "      loss = outputs[0]\n",
    "      # Find the total loss\n",
    "      loss_of_epoch += loss.item()\n",
    "\n",
    "    if (batch_idx+1) % print_every == 0:\n",
    "       print(\"Batch {:} / {:}\".format(batch_idx+1,len(val_loader)),\"\\nLoss:\", round(loss.item(),1),\"\\n\")\n",
    "\n",
    "  loss_of_epoch /= len(val_loader)\n",
    "  val_losses.append(loss_of_epoch)\n",
    "\n",
    "  # Print each epoch's time and train/val loss \n",
    "  print(\"\\n-------Epoch \", epoch+1,\n",
    "        \"-------\"\n",
    "        \"\\nTraining Loss:\", train_losses[-1],\n",
    "        \"\\nValidation Loss:\", val_losses[-1],\n",
    "        \"\\nTime: \",(time.time() - epoch_time),\n",
    "        \"\\n-----------------------\",\n",
    "        \"\\n\\n\")\n",
    "\n",
    "print(\"Total training and evaluation time: \", (time.time() - whole_train_eval_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2abf55bda1c53852352d4e16de7f91e46e9520816b382a01d9abf8d98ce130e3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
